{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week 7",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezaZJcL8HHV4"
      },
      "source": [
        "# Dog Classifier - Simple\n",
        "\n",
        "This week, we will build a simple neural network to classify different dog breeds!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL_kQxmJmnZM"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from net import DogNet\n",
        "from PIL import Image\n",
        "from stanford_dogs_data import DogsDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-amANWpuIQLY"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOtOkMoLnGs8"
      },
      "source": [
        "def load_data(plot=True, batch_size=32):\n",
        "  transform = transforms.Compose([transforms.Resize((32, 32)),\n",
        "                                  transforms.ToTensor(),\n",
        "                                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # means, stds\n",
        "                                  ])\n",
        "  train_dataset = DogsDataset(root=\"./data\", train=True, cropped=False, transform=transform, download=True)\n",
        "  test_dataset = DogsDataset(root=\"./data\", train=False, cropped=False, transform=transform, download=True)\n",
        "\n",
        "  train_loader = # TODO\n",
        "  test_loader = # TODO\n",
        "\n",
        "  classes = train_dataset.classes\n",
        "\n",
        "  if plot:\n",
        "    samples = random.sample(range(len(train_dataset)), batch_size)\n",
        "    images = [train_dataset[i][0].detach().numpy().transpose(1, 2, 0) for i in samples]\n",
        "    labels = [train_dataset[i][1] for i in samples]\n",
        "\n",
        "    fig = plt.figure(figsize=(batch_size/4 + 5, batch_size/4 + 5))  \n",
        "    for idx in np.arange(batch_size):\n",
        "        ax = fig.add_subplot(batch_size/8, 8, idx+1, xticks=[], yticks=[])\n",
        "        ax.imshow((images[idx] / 2) + 0.5)\n",
        "        ax.set_title(classes[labels[idx]], {'fontsize': batch_size/5}, pad=0.4)\n",
        "    plt.tight_layout(pad=1, w_pad=0, h_pad=0)\n",
        "    plt.show()\n",
        "\n",
        "  return train_loader, test_loader, classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXhAo9w_o9Cm"
      },
      "source": [
        "# Step 1 - Load the Stanford Dogs Dataset\n",
        "train_loader, test_loader, classes = load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZEMoZZ3IZND"
      },
      "source": [
        "## Neural Network Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r975mVh3qBHu"
      },
      "source": [
        "\"\"\"\n",
        "Build and train a model using given dataloader and provided hyperparameters.\n",
        "\"\"\"\n",
        "def train(dl, lr=0.01, momentum=0.9, num_epochs=5, save=True):\n",
        "  # set device\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "  # create model\n",
        "  model = DogNet()\n",
        "  model = model.to(device)\n",
        "\n",
        "  # initialize optimizers\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "  # train model\n",
        "  model.train()\n",
        "  for epoch in range(num_epochs):\n",
        "    running_loss = 0.0 # keep track of total loss in epoch\n",
        "    for i, (ims, labels) in enumerate(dl):\n",
        "      # move data to appropriate device\n",
        "      ims, labels = ims.to(device), labels.to(device)\n",
        "\n",
        "      # zero parameter gradients\n",
        "      # TODO\n",
        "\n",
        "      # forward pass\n",
        "      # TODO\n",
        "\n",
        "      # compute loss\n",
        "      # TODO\n",
        "\n",
        "      # backward pass\n",
        "      # TODO\n",
        "\n",
        "      # update parameters\n",
        "      # TODO\n",
        "\n",
        "      # print statistics\n",
        "      running_loss += loss.item()\n",
        "      if i % 45 == 44:\n",
        "        print(f\"Epoch: {epoch}, Batch Idx: {i}, Loss: {round(running_loss / 45, 3)}\")\n",
        "        running_loss = 0.0\n",
        "\n",
        "  if save:\n",
        "    torch.save(model.state_dict(), \"./dogNet.pth\")\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzksSKWvuePe"
      },
      "source": [
        "# Step 2 - Train your neural network on the training data\n",
        "model = train(train_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e5lBYNwIcbm"
      },
      "source": [
        "## Neural Network Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncxweIgrulGv"
      },
      "source": [
        "\"\"\"\n",
        "Test provided model on provided data in dataloader.\n",
        "\"\"\"\n",
        "def test(model, dl):\n",
        "  # set device\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "  # initialize variables\n",
        "  correct, total = 0, 0\n",
        "  class_correct, class_total = list(0. for i in range(120)), list(0. for i in range(120))\n",
        "\n",
        "  # set to evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  # ensure that a backward pass won't modify the gradient\n",
        "  with torch.no_grad():\n",
        "    for ims, labels in dl:\n",
        "      # move data to appropriate device\n",
        "      ims, labels = ims.to(device), labels.to(device)\n",
        "\n",
        "      # forward pass to compute prediction of batch\n",
        "      # TODO\n",
        "\n",
        "      # get predicted class from outputs\n",
        "      # TODO\n",
        "\n",
        "      # compute overall correctness (across classes)\n",
        "      correct += # TODO\n",
        "      total += labels.size(0)\n",
        "\n",
        "      # compute correctness per class\n",
        "      c = (predicted == labels).squeeze()\n",
        "      for i in range(c.shape[0]):\n",
        "        class_correct[labels[i]] += c[i].item()\n",
        "        class_total[labels[i]] += 1\n",
        "\n",
        "  print(f\"Overall Accuracy: {100 * (correct / total)}\")\n",
        "  for i in range(120):\n",
        "    print(f\"\\tAccuracy of {classes[i]}: {round(100 * (class_correct[i] / class_total[i]), 4)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP4zl3RV2BcI"
      },
      "source": [
        "# Step 3 - Evaluate your model on test data\n",
        "test(model, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Np2BM3usIerS"
      },
      "source": [
        "## Neural Network Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjN91saX19y2"
      },
      "source": [
        " \"\"\"\n",
        "Open image from given filepath, and use provided model to predict\n",
        "final classification decision.\n",
        "\"\"\"\n",
        "def predict(fname, model):\n",
        "  # load image and display\n",
        "  # TODO\n",
        "  display(im)\n",
        "\n",
        "  # resize and normalize\n",
        "  transform = transforms.Compose([transforms.Resize((32, 32)),\n",
        "                                  transforms.ToTensor(),\n",
        "                                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # means, stds\n",
        "                                  ])\n",
        "  # apply transform to image\n",
        "  # TODO\n",
        "\n",
        "  # detect device and move to appropriate device\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  im = im.to(device)\n",
        "  model.to(device)\n",
        "\n",
        "  # forward pass to get prediction\n",
        "  # TODO\n",
        "\n",
        "  # get predicted class from outputs\n",
        "  # TODO\n",
        "\n",
        "  # print final prediction\n",
        "  print(f\"Predicted {classes[predicted]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rDFXIoTIiFa"
      },
      "source": [
        "## Load Existing Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QP6gRw4F3i6"
      },
      "source": [
        "\"\"\" \n",
        "Given filename, loads existing neural network.\n",
        "\"\"\"\n",
        "def load_model(fname):\n",
        "  model = DogNet()\n",
        "  model.load_state_dict(torch.load(fname))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vG1AuM8M3M5k"
      },
      "source": [
        "# Step 4 - use model for prediction\n",
        "model = load_model(\"dogNet.pth\") \n",
        "predict(\"frankie.png\", model)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}